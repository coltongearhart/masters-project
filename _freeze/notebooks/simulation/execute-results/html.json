{
  "hash": "c577299e0b13229b83755518eb2d0d6b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Simulation\nauthor: Colton Gearhart\n---\n\n\n## Simulation\n\n### Setup\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# load packages\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(magrittr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(furrr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: future\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.8     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard()     masks purrr::discard()\n✖ magrittr::extract()   masks tidyr::extract()\n✖ dplyr::filter()       masks stats::filter()\n✖ recipes::fixed()      masks stringr::fixed()\n✖ dplyr::lag()          masks stats::lag()\n✖ magrittr::set_names() masks purrr::set_names()\n✖ yardstick::spec()     masks readr::spec()\n✖ recipes::step()       masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nset.seed(20)\n```\n:::\n\n\n### Correlation matrix\n      \nDefine functions to generate correlation matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# define function to generate correlation matrix of Xs\nmake_corr_x <- function(mc = c(\"ind\", \"low\", \"med-low\", \"med\"), p = 2) {\n  \n  # fill in upper triangle off diagonals of the correlation matrix\n  rho_xx = matrix(data = rep(NA, p^2), ncol = p)\n  for(i in 1:(p-1)) {\n    for (j in (i+1):p) {\n\n      # conditionally generate pairwise correlation coefficient\n      rho_xx[i,j] = \n        \n        if (identical(mc, \"ind\")){\n          \n          rep(0, 1)\n          \n        }else if (identical(mc, \"low\")){\n          \n          runif(n = 1, min = 0, max = 0.2)\n          \n        }else if (identical(mc, \"med-low\")){\n          \n          runif(n = 1, min = 0.2, max = 0.4)\n          \n        }else if (identical(mc, \"med\")){\n          \n          runif(n = 1, min = 0.4, max = 0.6)\n          \n        }\n    }\n  }\n  \n  # set diagonals of correlation matrix\n  diag(rho_xx) = 1\n  \n  # fill in lower triangle to be symmetric\n  rho_xx = Matrix::forceSymmetric(rho_xx)\n  \n  return(as.matrix(rho_xx))\n   \n}\n\n# test function\nmake_corr_x(mc = \"med-low\", p = 5)\n```\n:::\n\n\n### Simulation data\n\nDefine function to generate simulation dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# define function to simulate response and covariates\nmake_sim_data <- function(n = 100, p = 20, q = 10, b = 0.2, sigma = 1, mc = c(\"ind\", \"low\", \"med-low\", \"med\")){\n  \n  # set multicollinearity level\n  mc = match.arg(mc)\n  \n  # generate X correlation matrix\n  rho_xx = make_corr_x(mc, p)\n  \n  # generate covariates\n  X = MASS::mvrnorm(n = n, mu = rep(0, p), Sigma = rho_xx)\n  \n  # give column names\n  colnames(X) = paste0(\"x\", 1:p)\n  \n  # generate beta vector (q significant, non-zero parameters and p-q zeros)\n  beta = c(rep(b, q), rep(0, p-q))\n  \n  # calculate response\n  y = X %*% beta + rnorm(n, mean = 0, sd = sigma)\n  \n  # save as dataframe\n  data_sim = data.frame(y,X)\n  \n  return(data_sim)\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# test function\ntmp_data <- make_sim_data(n = 1000, p = 10, q = 5, b = 0.2, sigma = 1, mc = \"med\")\n```\n:::\n\n\n### Cross-validation\n\nDefine function to perform $k$-fold cross-validation: fit models on analysis data and predict for assessment data.\n\nThen summarize each folds with the prediction measures.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# for a single iteration\n# perform 5-fold cross validation\n\n# split data into 5 folds\nkfolds <- rsample::vfold_cv(data = tmp_data, v = 5, repeats = 1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# function to:\n# 1) fit model on analysis data\n# 2) make predictions on holdout data\n# ... will be the model formula\nholdout_results <- function(splits, ...) {\n  \n  # fit the model to the analysis data (k-1 folds)\n  mod_kfold = lm(..., data = rsample::analysis(splits))\n  \n  # save the holdout data (last fold)\n  data_holdout = rsample::assessment(splits)\n  \n  # `augment` will save the predictions with the holdout data set\n  preds = augment(mod_kfold, newdata = data_holdout)\n  \n  return(preds)\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# fit models for k-fold cross validation\nkfolds$preds <- kfolds$splits %>% map(holdout_results, formula(y ~ -1 + .))\n\n# calculate testing metrics for each fold\nkfolds$results <- kfolds$preds %>% map(function(df) {\n  data.frame(rmse = yardstick::rmse_vec(truth = df$y,estimate = df$`.fitted`),\n             rsq = yardstick::rsq_vec(truth = df$y, estimate = df$`.fitted`))\n})\n\n# calculate final cross validation metrics\nkfolds$results %>% \n  bind_rows %>% \n  summarize(across(everything(), mean))\n```\n:::\n\n\n### Set paramaters\n\nSetup simulation structure.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# initialize simulation settings with repeated iterations\n# -> first the parameters of interest (constants are specified later in simulation)\n# -> create all combos (+ iterations)\n# -> add simulation id column\n# -> organize\nparams_i <- expand.grid(n = seq(from = 30, to = 300, by = 10),\n                        p = c(3, 6, 9),\n                        q_ratio = c(\"1/3\", \"2/3\", \"3/3\"),\n                        mc = c(\"ind\", \"low\", \"med-low\", \"med\"),\n                        i = 1:500) %>% \n  data.frame %>% \n  group_by(n, p, q_ratio, mc) %>% \n  mutate(sim_id = cur_group_id()) %>% \n  ungroup %>% \n  arrange(sim_id, i)\n\n# calculate specifics and organize\nparams_i %<>% mutate(\n  q = case_when(\n    q_ratio == \"1/3\" ~ p/3,\n    q_ratio == \"2/3\" ~ 2*p/3,\n    q_ratio == \"3/3\" ~ p\n  ),\n  mc = as.character(mc) # needed for match.args()\n) %>% \n  select(sim_id, i, n, p, q_ratio, q, mc)\n\n# nest simulation settings into dataframe\nsimulation <- params_i %>% \n  nest(.by = c(sim_id, i)) %>% \n  rename(params = data)\n```\n:::\n\n\n### Run simulation\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# run simulation\ntictoc::tic()\n\n# setup plan\nplan(multisession, workers = availableCores()-4)\n\n# generate data according to each simulation setting\n# -> specify constant values in simulation (non-variable settings)\nsimulation$data <- simulation$params %>% future_map(function(params) {\n  params %$% make_sim_data(n, p, q, mc, b = 0.2, sigma = 1)\n}, .progress = TRUE, .options=furrr_options(seed = TRUE))\n\n# split each dataset into 5 folds\nsimulation$kfolds <- simulation$data %>% map(\\(df) rsample::vfold_cv(df, v = 5, repeats = 1), .progress = TRUE)\n\n# loop through each iteration to work on each set of kfolds\nfor (j in 1:nrow(simulation)) {\n  \n  # extract resample dataframe\n  kfolds = simulation[j, \"kfolds\"]$kfolds[[1]]\n  \n  # fit models for k-fold cross-validation\n  preds = kfolds$splits %>% map(\\(split) holdout_results(split, formula(y ~ -1 + .)))\n  \n  # calculate predictions for each fold\n  results = preds %>% map(function(df) {\n    data.frame(rmse = yardstick::rmse_vec(truth = df$y,estimate = df$`.fitted`),\n               rsq = yardstick::rsq_vec(truth = df$y, estimate = df$`.fitted`))\n  })\n  \n  # summarize cross-validation results\n  simulation[j, \"results_cv\"] <- nest(\n    results %>% \n    bind_rows %>% \n    summarize(across(everything(), mean))\n  )\n  \n  if (j %% 100 == 0)\n    print(j)\n  \n}\n\nsave(simulation, file = \"files/simulation.RData\")\ntictoc::toc()\n```\n:::\n\n\n## Results\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\n# create results dataframe\n# -> select simulation identifiers then unnest\n# -> aggregate over iterations\nresults <- simulation %>% \n  select(sim_id, i, params, results_cv) %>% \n  unnest(cols = c(params, results_cv)) %>% \n  summarize(.by = c(sim_id, n, p, q_ratio, q, mc),\n            across(c(rmse, rsq), list(mean = mean, sd = sd)))\n\nsave(results, file = \"files/results.RData\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nload(\"/Users/coltongearhart/Desktop/masters-project/files/results.RData\")\n\n# set rules and the corresponding sample sizes\nrules <- expand.grid(rule = c(\"10p\", \"10.8p + 11.8\", \"15p\", \"30p\", \"10p + 30\", \"p + 50\", \"8p + 50\"),\n                     p = c(3, 6, 9)) %>% \n  mutate(\n    n = case_when(\n      rule == \"10p\" ~ 10*p,\n      rule == \"10.8p + 11.8\" ~ ceiling(10.8*p + 11.8),\n      rule == \"15p\" ~ 15*p,\n      rule == \"30p\" ~ 30*p,\n      rule == \"10p + 30\" ~ 10*p + 30,\n      rule == \"p + 50\" ~ p + 50,\n      rule == \"8p + 50\" ~ 8*p + 50,\n    )\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: fig_all_rmse\n\n# all rmse plot (panels of q ratio by p and colored by mc level)\n# -> with added rules of thumb\nresults %>% \n  ggplot(aes(x = n,\n             y = rmse_mean,\n             group = factor(mc, levels = c(\"ind\", \"low\", \"med-low\", \"med\")),\n             color = factor(mc, levels = c(\"ind\", \"low\", \"med-low\", \"med\")))) + \n  geom_point() + \n  geom_line() +\n  geom_vline(aes(xintercept = n),\n             data = rules,\n             color = \"orange\",\n             alpha = 0.5) + \n  scale_color_brewer() + \n  facet_grid(q_ratio ~ factor(p)) + \n  labs(x = expression(\"Sample size \" * italic(\"n\")),\n       y = expression(italic(\"RMSE\")),\n      color = \"Multicollinearity level\") + \n  theme_bw() + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/fig_all_rmse-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# focused rmse plot\n# -> just using all active cause no q ratio effect\np_rmse <- results %>% \n  filter(q_ratio == \"3/3\") %>% \n  ggplot(aes(x = n,\n             y = rmse_mean,\n             group = factor(mc, levels = c(\"ind\", \"low\", \"med-low\", \"med\")),\n             color = factor(mc, levels = c(\"ind\", \"low\", \"med-low\", \"med\")))) + \n  geom_point() + \n  geom_line() +\n  geom_vline(aes(xintercept = n),\n             data = rules,\n             color = \"orange\",\n             alpha = 0.5) + \n  scale_color_brewer() + \n  facet_grid(q_ratio ~ factor(p)) + \n  labs(x = expression(\"Sample size \" * italic(\"n\")),\n       y = expression(italic(\"RMSE\")),\n       color = \"Multicollinearity level\") + \n  theme_bw() + \n  theme(legend.position = \"bottom\")\n  \n# find the average rmse (across mc levels) from the min sample size rule to the second max\nresults %>% \n  filter(p == 9, q_ratio == \"3/3\", n %in% c(60, 140)) %>% \n  summarize(.by = n,\n            mean(rmse_mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n      n `mean(rmse_mean)`\n  <dbl>             <dbl>\n1    60              1.09\n2   140              1.03\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| eval: false\n\nggsave(\"files/plot-rmse-focused.png\", p_rmse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# all rmse plot (panels of q ratio by mc level and colored by p)\nresults %>% \n  #filter(q_ratio == \"3/3\") %>% \n  ggplot(aes(x = n,\n             y = rmse_mean,\n             group = factor(p),\n             color = factor(p))) + \n  geom_point() + \n  geom_line() + \n  scale_color_brewer() + \n  facet_grid(q_ratio ~ factor(mc, levels = c(\"ind\", \"low\", \"med-low\", \"med\"))) + \n  labs(x = expression(\"Sample size \" * italic(\"n\")),\n       y = expression(italic(\"RMSE\")),\n       color = expression(italic(\"p\"))) + \n  theme_bw() + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code .hidden}\n# this shows same information as previous all plot\n# -> same across mc levels, and p is driving the differences (not much affect of q ratio)\n```\n:::\n\n::: {.cell}\n\n:::",
    "supporting": [
      "simulation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}